{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ad12793",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Getting Real - Investigating a published ephys dataset\n",
    "Based on tutorial material by Julia Sprenger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d4f389",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Reach-2-Grasp experiment\n",
    "\n",
    "![R2G_overview](reach_to_grasp_material/R2G_task_overview.png)\n",
    "\n",
    "Full data manuscript and dataset\n",
    "- Brochier, T., Zehl, L., Hao, Y., Duret, M., Sprenger, J., Denker, M., Gr√ºn, S. & Riehle, A. (2018). Massively parallel recordings in macaque motor cortex during an instructed delayed reach-to-grasp task, Scientific Data, 5, 180055. http://doi.org/10.1038/sdata.2018.55\n",
    "- https://gin.g-node.org/INT/multielectrode_grasp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7319580",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Neuronal data sources\n",
    "<img src=\"reach_to_grasp_material/R2G_arrays.jpg\" width=\"500\"/>\n",
    "Black numbers indicate the connector-aligned IDs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd00c42",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Data and metadata sources\n",
    "<img src=\"reach_to_grasp_material/R2G_files.png\" width=\"700\"/>\n",
    "\n",
    "A compiled version of a part of this dataset including metadata is available in the shared google drive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72309fcf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dataset overview - General\n",
    "We can directly get an overview of the contained objects from the `neo.Block` print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a76ae878",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Block with 1 segments\n",
       "name: 'Reach2Grasp data'\n",
       "annotations: {'nix_name': 'neo.block.6aa7b5491ab74067aee4183310955892'}\n",
       "rec_datetime: datetime.datetime(2021, 8, 25, 21, 3, 51)\n",
       "# segments (N=1)\n",
       "0: Segment with 1 analogsignals, 1 events, 271 spiketrains\n",
       "   name: 'Segment 0'\n",
       "   description: 'Segment containing data from t_start to t_stop'\n",
       "   annotations: {'nix_name': 'neo.segment.1c1ad7987ca048efa7b433b4e87e0f71',\n",
       "     'condition': 1}\n",
       "   # analogsignals (N=1)\n",
       "   0: AnalogSignal with 96 channels of length 74455; units uV; datatype float32 \n",
       "      name: 'Channel bundle (chan1,chan2,chan3,chan4,chan5,chan6,chan7,chan8,chan9,chan10,chan11,chan12,chan13,chan14,chan15,chan16,chan17,chan18,chan19,chan20,chan21,chan22,chan23,chan24,chan25,chan26,chan27,chan28,chan29,chan30,chan31,chan32,chan33,chan34,chan35,chan36,chan37,chan38,chan39,chan40,chan41,chan42,chan43,chan44,chan45,chan46,chan47,chan48,chan49,chan50,chan51,chan52,chan53,chan54,chan55,chan56,chan57,chan58,chan59,chan60,chan61,chan62,chan63,chan64,chan65,chan66,chan67,chan68,chan69,chan70,chan71,chan72,chan73,chan74,chan75,chan76,chan77,chan78,chan79,chan80,chan81,chan82,chan83,chan84,chan85,chan86,chan87,chan88,chan89,chan90,chan91,chan92,chan93,chan94,chan95,chan96) '\n",
       "      annotations: {'nix_name': 'neo.analogsignal.18037944fdf2472d9c49cff8ea26e4ff',\n",
       "        'neural_signal': True,\n",
       "        'filter_shift_correction': array(2.1) * ms}\n",
       "      sampling rate: 1000.0 Hz\n",
       "      time: -0.00010000000000000026 s to 74.4549 s"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import neo\n",
    "filename = 'reach_to_grasp_material/i140703-001.nix'\n",
    "with neo.io.NixIO(filename, 'ro') as io:\n",
    "    block = io.read_block()\n",
    "block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6213f01",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This summary already tells us that we only need to take care of a single segment with one event, one analogsignal and multiple spiketrain objects. The 96 continuously sampled channels are sampled a 'low' sampling rate of 1kHz and contain neural data, so data comparable to local-field potential measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15de13b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dataset overview - SpikeTrains\n",
    "To learn more about the spiketrains, we print the spiketrain annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02a207fc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nix_name': 'neo.spiketrain.22a41c20c0614a238d32dea2d46673ca',\n",
       " 'id': 'Unit 1000',\n",
       " 'channel_id': 1,\n",
       " 'unit_id': 0,\n",
       " 'unit_tag': 'unclassified',\n",
       " 'electrode_reject_HFC': False,\n",
       " 'electrode_reject_LFC': False,\n",
       " 'electrode_reject_IFC': False,\n",
       " 'connector_aligned_id': 93,\n",
       " 'coordinate_x': array(0.8) * mm,\n",
       " 'coordinate_y': array(3.6) * mm,\n",
       " 'sua': False,\n",
       " 'mua': False,\n",
       " 'noise': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment = block.segments[0]\n",
    "segment.spiketrains[0].annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fb14fe",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "## Dataset overview - AnalogSignals\n",
    "To learn more about the channels of the analogsignal, we print the entries of the array_annotations of the single analogsignal object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5e4a903",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['channel_names', 'channel_ids', 'file_origin', 'connector_ID', 'connector_pinID', 'nev_dig_factor', 'nb_sorted_units', 'nev_hi_freq_order', 'nev_hi_freq_type', 'nev_lo_freq_order', 'nev_lo_freq_type', 'nsx_hi_freq_order', 'nsx_lo_freq_order', 'nsx_hi_freq_type', 'nsx_lo_freq_type', 'description', 'nsx', 'hi_pass_freq', 'lo_pass_freq', 'hi_pass_order', 'lo_pass_order', 'filter_type', 'electrode_reject_HFC', 'electrode_reject_LFC', 'electrode_reject_IFC', 'connector_aligned_ids', 'coordinates_x', 'coordinates_y'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment.analogsignals[0].array_annotations.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5111b21f",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We see that both, spiketrains as well as channels are annotated with a 'connector_aligned_id', indicating the spatial source of the signal. In addition the coordinates in x and y direction are provided in physical units for each channel and spiketrain. Spiketrains also carry information about 'noise', 'mua' or 'sua' assignment, indicating that the spikes were spikesorted and assigned to one of the three unit categories:\n",
    "- *noise*: non-neural threshold crossing events)\n",
    "- *mua*: multi-unit-activity - neural threshold crossing events that can not be uniquely assigned to a virtual neuron unit\n",
    "- *sua*: single-unit-activity - neural threshold crossing events that are assigned to a single virtual neuron unit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59207d6c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dataset overview - Events\n",
    "To learn more about the events, we print the labels and annotations of the single event object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "765fde73",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event object name: TrialEvents\n",
      "Number of event times: 192\n",
      "Unique event labels: ['CUE-OFF' 'CUE-ON' 'DO' 'FSRplat-OFF' 'FSRplat-ON' 'GO-ON' 'HEplat-OFF'\n",
      " 'HEplat-ON' 'OBB' 'OR' 'OT' 'RW-OFF' 'RW-ON' 'RW-ON-REP' 'SR' 'SR-REP'\n",
      " 'STOP' 'TS-ON' 'WS-ON']\n",
      "Event annotation keys: dict_keys(['trial_id', 'trial_timestamp_id', 'performance_in_trial', 'performance_in_trial_str', 'belongs_to_trialtype', 'trial_event_labels', 'trial_reject_HFC', 'trial_reject_LFC', 'trial_reject_IFC'])\n",
      "Unique trial_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "Number of reward-on events: 11\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "event = segment.events[0]\n",
    "print(f'Event object name: {event.name}')\n",
    "print(f'Number of event times: {len(event)}')\n",
    "print(f'Unique event labels: {np.unique(event.labels)}')\n",
    "print(f'Event annotation keys: {event.array_annotations.keys()}')\n",
    "print(f'Unique trial_ids: {np.unique(event.array_annotations[\"trial_id\"])}')\n",
    "print(f'Number of reward-on events: {sum(event.labels==\"RW-ON\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e0705c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Working with a dataset - Neo methods and utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d3277a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In the following lines we are going to introduce a set of useful features of neo objects while cutting the dataset into individual trial segments. Based on the trial events and their annotations we can identify successful (correct) trials and select the time around the start of the trial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876b5fc5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Filtering for event objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27ce9e97",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "events = block.filter(objects='Event', name='TrialEvents')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e95b3c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Masking Neo objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cab7af",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "First we are selecting event times that are occurring during successful trials, marked by the `performance_in_trial_str` as `correct_trial`. In addition we also only want to select trial start (`TS-ON`) events. Based on the array annotations we are creating two masks and apply both to the original event to generate a new event object via slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe323fd4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "mask1 = event.array_annotations['performance_in_trial_str'] == 'correct_trial'\n",
    "mask2 = event.array_annotations['trial_event_labels'] == 'TS-ON'\n",
    "correct_TS_event = event[mask1 & mask2]\n",
    "print(len(correct_TS_event))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6096013b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "start_event = correct_TS_event"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5747d87",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Utility function: Epoch creation\n",
    "In the next step we are making use of neo utility functions to generate epochs around the time points extracted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f046bf8a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Construct analysis epochs from 10ms before the TS-ON of a successful behavioral trial to 15ms after TS-ON. The name \"analysis_epochs\" is given to the resulting Neo Epoch object. The object is not attached to the Neo Segment. The parameter event2 of add_epoch() is left empty, since we are cutting around a single event, as opposed to cutting between two events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "192dd147",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from neo.utils import add_epoch\n",
    "import quantities as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daabfccf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pre = -10 * pq.ms\n",
    "post = 15 * pq.ms\n",
    "epoch = add_epoch(\n",
    "    segment,\n",
    "    event1=start_event, event2=None,\n",
    "    pre=pre, post=post,\n",
    "    attach_result=False,\n",
    "    name='analysis_epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ae63ef",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The number of epochs generated is the same as the number of trial start events and all epochs have the same duration as we extract 25ms of data around each trial start event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adf48780",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs: 11\n",
      "Durations of epochs: [0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025] s\n"
     ]
    }
   ],
   "source": [
    "print('Number of epochs: {}'.format(len(epoch)))\n",
    "print('Durations of epochs: {}'.format(epoch.durations))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bfe04d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Utility function: cutting segment by epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0a7841",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "\n",
    "Now we use the previously defined epochs to cut the segment containing the complete dataset into subsets, where each new segment corresponds to the starting epoch of a successful trial. For capturing the newly generated segments, we create a new Neo block.\n",
    "\n",
    "Create new segments of data cut according to the analysis epochs of the 'analysis_epochs' Neo Epoch object. The time axes of all segments are aligned such that each segment starts at time 0 (parameter reset_times); annotations describing the analysis epoch are carried over to the segments. A new Neo Block named \"data_cut_to_analysis_epochs\" is created to capture all cut analysis epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42d33b10",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from neo.utils import cut_segment_by_epoch\n",
    "\n",
    "cut_trial_block = neo.Block(name=\"data_cut_to_analysis_epochs\")\n",
    "cut_trial_block.segments = cut_segment_by_epoch(segment, epoch, reset_time=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f58bca34",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cut_trial_block.segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02812eaa",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can confirm that the resetting of the times during the segmentation process was successfull by checking the new times of the trial start events in the new segments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c34c004",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the new trial TS is happening at [array(0.01) * s, array(0.01) * s, array(0.01) * s, array(0.01) * s, array(0.01) * s, array(0.01) * s, array(0.01) * s, array(0.01) * s, array(0.01) * s, array(0.01) * s, array(0.01) * s]\n"
     ]
    }
   ],
   "source": [
    "print('In the new trial TS is happening at {}'.format([s.events[-1][0] for s in cut_trial_block.segments]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9481033e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### More interesting features\n",
    "- *`DataObject`*`.time_slice()` - create a new object containing data in a subset of the original time span -- works also for containers!\n",
    "- *`Object`*`.annotate()` - adding a custom annotation\n",
    "- *`DataObject`*`.array_annotate()` - adding a custom array annotation (channel / spike based annotation)\n",
    "- *`DataObject`*`.merge()` - merge data values of two DataObjects\n",
    "- *`DataObject`*`.concatenate()` - concatenate data values of two DataObjects\n",
    "- `AnalogSignal.downsample()` - create an AnalogSignal with a lower sampling rate\n",
    "- *`Object`*`.parents`, e.g. `AnalogSignal.segment` - to navigate in neo object structure\n",
    "- *`Quantity`*`.rescale()` - rescale the data to a new physical unit, e.g., `.rescale(pq.ms)` to rescale to milliseconds\n",
    "- *`Quantity`*`.simplified()` - simplifies units to SI units\n",
    "- *`Quantity`*`.dimensionality.latex` - get latex representation of physical unit (for plotting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaad6d8-926a-4a0a-97fa-cffc48046588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "livereveal": {
   "autolaunch": true,
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
